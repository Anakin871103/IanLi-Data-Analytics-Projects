# XGBoost æ¨¡å‹æ¨è«–ç¯„ä¾‹
import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.datasets import load_breast_cancer

def load_trained_model():
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹å’Œé è™•ç†å™¨"""
    try:
        # è¼‰å…¥XGBoostæ¨¡å‹
        model = xgb.XGBClassifier()
        model.load_model('xgboost_model.json')
        
        # è¼‰å…¥æ¨™æº–åŒ–å™¨
        scaler = joblib.load('scaler.pkl')
        
        print("âœ… æ¨¡å‹å’Œé è™•ç†å™¨è¼‰å…¥æˆåŠŸ")
        return model, scaler
    
    except FileNotFoundError as e:
        print(f"âŒ æª”æ¡ˆæœªæ‰¾åˆ°: {e}")
        print("è«‹å…ˆåŸ·è¡Œ xgboost_project.py ä¾†è¨“ç·´æ¨¡å‹")
        return None, None

def predict_single_sample(model, scaler, sample_data):
    """å°å–®ä¸€æ¨£æœ¬é€²è¡Œé æ¸¬"""
    # æ¨™æº–åŒ–è¼¸å…¥è³‡æ–™
    sample_scaled = scaler.transform([sample_data])
    
    # é æ¸¬é¡åˆ¥
    prediction = model.predict(sample_scaled)[0]
    
    # é æ¸¬æ©Ÿç‡
    probability = model.predict_proba(sample_scaled)[0]
    
    return prediction, probability

def predict_batch(model, scaler, batch_data):
    """å°æ‰¹æ¬¡è³‡æ–™é€²è¡Œé æ¸¬"""
    # æ¨™æº–åŒ–è¼¸å…¥è³‡æ–™
    batch_scaled = scaler.transform(batch_data)
    
    # é æ¸¬é¡åˆ¥
    predictions = model.predict(batch_scaled)
    
    # é æ¸¬æ©Ÿç‡
    probabilities = model.predict_proba(batch_scaled)
    
    return predictions, probabilities

def demo_inference():
    """ç¤ºç¯„æ¨¡å‹æ¨è«–"""
    print("ğŸ”® XGBoost æ¨¡å‹æ¨è«–ç¤ºç¯„")
    print("=" * 50)
    
    # è¼‰å…¥æ¨¡å‹
    model, scaler = load_trained_model()
    if model is None:
        return
    
    # è¼‰å…¥æ¸¬è©¦è³‡æ–™
    data = load_breast_cancer()
    X = data.data
    y = data.target
    feature_names = data.feature_names
    
    print(f"è¼‰å…¥æ¸¬è©¦è³‡æ–™: {X.shape[0]} å€‹æ¨£æœ¬, {X.shape[1]} å€‹ç‰¹å¾µ")
    
    # ç¤ºç¯„1: å–®ä¸€æ¨£æœ¬é æ¸¬
    print("\nğŸ“ ç¤ºç¯„1: å–®ä¸€æ¨£æœ¬é æ¸¬")
    print("-" * 30)
    
    sample_idx = 0
    sample = X[sample_idx]
    actual_label = y[sample_idx]
    
    prediction, probability = predict_single_sample(model, scaler, sample)
    
    print(f"æ¨£æœ¬ç´¢å¼•: {sample_idx}")
    print(f"å¯¦éš›æ¨™ç±¤: {actual_label} ({'è‰¯æ€§' if actual_label == 1 else 'æƒ¡æ€§'})")
    print(f"é æ¸¬æ¨™ç±¤: {prediction} ({'è‰¯æ€§' if prediction == 1 else 'æƒ¡æ€§'})")
    print(f"é æ¸¬æ©Ÿç‡: æƒ¡æ€§={probability[0]:.4f}, è‰¯æ€§={probability[1]:.4f}")
    print(f"é æ¸¬{'æ­£ç¢º' if prediction == actual_label else 'éŒ¯èª¤'} âœ…" if prediction == actual_label else "é æ¸¬éŒ¯èª¤ âŒ")
    
    # ç¤ºç¯„2: æ‰¹æ¬¡é æ¸¬
    print("\nğŸ“ ç¤ºç¯„2: æ‰¹æ¬¡é æ¸¬ (å‰10å€‹æ¨£æœ¬)")
    print("-" * 40)
    
    batch_size = 10
    batch_X = X[:batch_size]
    batch_y = y[:batch_size]
    
    predictions, probabilities = predict_batch(model, scaler, batch_X)
    
    print(f"{'ç´¢å¼•':<4} {'å¯¦éš›':<4} {'é æ¸¬':<4} {'æƒ¡æ€§æ©Ÿç‡':<8} {'è‰¯æ€§æ©Ÿç‡':<8} {'çµæœ':<4}")
    print("-" * 50)
    
    correct_count = 0
    for i in range(batch_size):
        actual = batch_y[i]
        pred = predictions[i]
        prob_malignant = probabilities[i][0]
        prob_benign = probabilities[i][1]
        is_correct = "âœ…" if pred == actual else "âŒ"
        
        if pred == actual:
            correct_count += 1
            
        print(f"{i:<4} {actual:<4} {pred:<4} {prob_malignant:<8.4f} {prob_benign:<8.4f} {is_correct:<4}")
    
    accuracy = correct_count / batch_size
    print(f"\næ‰¹æ¬¡æº–ç¢ºç‡: {accuracy:.2%} ({correct_count}/{batch_size})")
    
    # ç¤ºç¯„3: ç‰¹å¾µé‡è¦æ€§åˆ†æ
    print("\nğŸ“ ç¤ºç¯„3: æ¨¡å‹ç‰¹å¾µé‡è¦æ€§ (å‰10å)")
    print("-" * 40)
    
    feature_importance = model.feature_importances_
    
    # å–å¾—å‰10å€‹æœ€é‡è¦çš„ç‰¹å¾µ
    top_indices = np.argsort(feature_importance)[-10:][::-1]
    
    print(f"{'æ’å':<4} {'ç‰¹å¾µåç¨±':<25} {'é‡è¦æ€§åˆ†æ•¸':<10}")
    print("-" * 45)
    
    for rank, idx in enumerate(top_indices, 1):
        feature_name = feature_names[idx]
        importance = feature_importance[idx]
        print(f"{rank:<4} {feature_name:<25} {importance:<10.4f}")
    
    # ç¤ºç¯„4: è‡ªå®šç¾©é æ¸¬å‡½æ•¸
    print("\nğŸ“ ç¤ºç¯„4: è‡ªå®šç¾©é æ¸¬å‡½æ•¸")
    print("-" * 30)
    
    def predict_with_explanation(sample_data, threshold=0.5):
        """å¸¶è§£é‡‹çš„é æ¸¬å‡½æ•¸"""
        prediction, probability = predict_single_sample(model, scaler, sample_data)
        
        confidence = max(probability)
        predicted_class = "è‰¯æ€§" if prediction == 1 else "æƒ¡æ€§"
        
        if confidence > 0.9:
            confidence_level = "éå¸¸é«˜"
        elif confidence > 0.8:
            confidence_level = "é«˜"
        elif confidence > 0.7:
            confidence_level = "ä¸­ç­‰"
        else:
            confidence_level = "ä½"
        
        return {
            'prediction': prediction,
            'predicted_class': predicted_class,
            'probability': probability,
            'confidence': confidence,
            'confidence_level': confidence_level
        }
    
    # æ¸¬è©¦è‡ªå®šç¾©å‡½æ•¸
    sample_idx = 5
    result = predict_with_explanation(X[sample_idx])
    
    print(f"æ¨£æœ¬ {sample_idx} é æ¸¬çµæœ:")
    print(f"- é æ¸¬é¡åˆ¥: {result['predicted_class']}")
    print(f"- ä¿¡å¿ƒåº¦: {result['confidence']:.4f} ({result['confidence_level']})")
    print(f"- è©³ç´°æ©Ÿç‡: æƒ¡æ€§={result['probability'][0]:.4f}, è‰¯æ€§={result['probability'][1]:.4f}")

if __name__ == "__main__":
    demo_inference()