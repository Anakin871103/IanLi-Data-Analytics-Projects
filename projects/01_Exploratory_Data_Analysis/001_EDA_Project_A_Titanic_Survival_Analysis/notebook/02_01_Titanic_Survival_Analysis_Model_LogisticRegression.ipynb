{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鐵達尼號生還預測：羅吉斯迴歸模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境準備\n",
    "導入所需的套件，並從我們建立的 `data_preprocessing.py` 腳本中導入資料準備函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_modeling(\n",
    "    cleaned_data_path, \n",
    "    features_to_drop, \n",
    "    target_column, \n",
    "    test_size=0.2, \n",
    "    random_state=42):\n",
    "    \"\"\"\n",
    "    從清理後的數據載入資料，進行特徵編碼和資料分割，為模型訓練做準備。\n",
    "\n",
    "    Args:\n",
    "        cleaned_data_path (str): train_cleaned.csv 檔案的路徑。\n",
    "        features_to_drop (list): 需要從特徵集中移除的欄位列表。\n",
    "        target_column (str): 目標變數的欄位名稱。\n",
    "        test_size (float): 分割給測試集的資料比例。\n",
    "        random_state (int): 亂數種子，確保每次分割結果一致。\n",
    "\n",
    "    Returns:\n",
    "        tuple: 回傳 (X_train, X_test, y_train, y_test)\n",
    "        X_train 訓練用的特徵\n",
    "        X_test  測試用的特徵\n",
    "        y_train 訓練用的答案\n",
    "        y_test  測試用的答案\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # 載入清理後的資料\n",
    "    df = pd.read_csv(cleaned_data_path)\n",
    "\n",
    "    # --- 特徵編碼 ---\n",
    "    # 對指定的類別欄位進行 One-Hot Encoding\n",
    "    # drop_first=True 可以避免共線性問題\n",
    "    categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Age_Group']\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "    ## df, 須處裡的 dataframe\n",
    "    ## columns=categorical_features, 須處裡的欄位\n",
    "    ## drop_first=True, 為了避免「共線性」（dummy variable trap），我們會捨棄每個特徵轉換後的第一個類別欄位。例如，如果Sex有'female'和'male' 兩類，get_dummies 只會產生 Sex_male 這一欄，因為當Sex_male 為 0 時，就隱含了該乘客是 'female'。\n",
    "    \n",
    "    # --- 定義特徵(X)與目標(y) ---\n",
    "    # 定義目標變數 y [（'Survived'）- 是否生還]\n",
    "    y = df_encoded[target_column]\n",
    "\n",
    "    # 從編碼後的 df 中移除目標變數和指定的其他欄位，得到特徵集 X\n",
    "    X = df_encoded.drop(columns=[target_column] + features_to_drop, axis=1)\n",
    "    \n",
    "    # 確保所有特徵都是數值型態\n",
    "    X = X.apply(pd.to_numeric)\n",
    "\n",
    "    # --- 資料分割 ---\n",
    "    # 將資料分割為訓練集與測試集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料準備\n",
    "呼叫 `prepare_data_for_modeling` 函式來載入資料、進行特徵編碼和分割，為模型訓練做好準備。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義清理後資料檔案的路徑和目標欄位\n",
    "# 相對於 Notebook 的路徑: projects/01_Exploratory_Data_Analysis/001_EDA_Project_A_Titanic_Survival_Analysis/data/train_cleaned.csv\n",
    "cleaned_data_path = '../data/train_cleaned.csv'\n",
    "target_column = 'Survived'\n",
    "\n",
    "# 這些是不具預測性的 ID 或已被轉換/合併的原始欄位\n",
    "features_to_drop = ['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch', 'Fare', 'Age']\n",
    "\n",
    "# 執行資料準備函式\n",
    "X_train, X_test, y_train, y_test = prepare_data_for_modeling(\n",
    "    cleaned_data_path,\n",
    "    features_to_drop=features_to_drop,\n",
    "    target_column=target_column\n",
    ")\n",
    "\n",
    "print(\"資料準備完成！\")\n",
    "print(f\"訓練集特徵數量: {X_train.shape[1]}\")\n",
    "print(f\"訓練集樣本數: {X_train.shape[0]}\")\n",
    "print(f\"測試集樣本數: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型訓練與評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化羅吉斯迴歸模型\n",
    "# max_iter 增加迭代次數以確保收斂，random_state 確保結果可重現\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 使用訓練集進行模型訓練\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 在測試集上進行預測\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"模型訓練與預測完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型效能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"模型準確率 (Accuracy): {accuracy:.4f}\")\n",
    "print(\"混淆矩陣 (Confusion Matrix):\")\n",
    "print(conf_matrix)\n",
    "print(\"分類報告 (Classification Report):\")\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnalysisProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
