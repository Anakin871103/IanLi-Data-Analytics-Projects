{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鐵達尼號生還預測：ROC曲線分析（修正版）\n",
    "\n",
    "本筆記本專門處理原始資料中的缺失值問題：\n",
    "- Cabin: 大量缺失值\n",
    "- Age: 部分缺失值\n",
    "- Embarked: 少量缺失值\n",
    "- Fare: 測試資料中可能有缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    roc_curve, auc, roc_auc_score, f1_score, precision_score, \n",
    "    recall_score, precision_recall_curve\n",
    ")\n",
    "\n",
    "# 設定中文字體和圖表樣式\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"環境準備完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料預處理函式（針對缺失值優化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, dataset_name=\"資料集\"):\n",
    "    \"\"\"\n",
    "    分析資料集中的缺失值情況\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {dataset_name} 缺失值分析 ===\")\n",
    "    missing_count = df.isnull().sum()\n",
    "    missing_percent = (missing_count / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        '缺失數量': missing_count,\n",
    "        '缺失百分比': missing_percent\n",
    "    })\n",
    "    \n",
    "    # 只顯示有缺失值的欄位\n",
    "    missing_df = missing_df[missing_df['缺失數量'] > 0].sort_values('缺失數量', ascending=False)\n",
    "    \n",
    "    if len(missing_df) > 0:\n",
    "        print(missing_df)\n",
    "    else:\n",
    "        print(\"沒有發現缺失值\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "\n",
    "def preprocess_titanic_data(df, dataset_name=\"資料集\"):\n",
    "    \"\"\"\n",
    "    對Titanic資料進行完整的預處理，重點處理缺失值\n",
    "    \"\"\"\n",
    "    print(f\"\\n開始處理 {dataset_name}...\")\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 分析原始缺失值\n",
    "    analyze_missing_values(data, f\"{dataset_name}（原始）\")\n",
    "    \n",
    "    # 2. 處理缺失值\n",
    "    print(f\"\\n處理 {dataset_name} 的缺失值...\")\n",
    "    \n",
    "    # Age: 用中位數填補\n",
    "    if data['Age'].isnull().any():\n",
    "        age_median = data['Age'].median()\n",
    "        age_missing_count = data['Age'].isnull().sum()\n",
    "        data['Age'].fillna(age_median, inplace=True)\n",
    "        print(f\"✓ Age: {age_missing_count} 個缺失值用中位數 {age_median:.1f} 填補\")\n",
    "    \n",
    "    # Embarked: 用眾數填補\n",
    "    if data['Embarked'].isnull().any():\n",
    "        embarked_mode = data['Embarked'].mode()[0]\n",
    "        embarked_missing_count = data['Embarked'].isnull().sum()\n",
    "        data['Embarked'].fillna(embarked_mode, inplace=True)\n",
    "        print(f\"✓ Embarked: {embarked_missing_count} 個缺失值用眾數 '{embarked_mode}' 填補\")\n",
    "    \n",
    "    # Fare: 用中位數填補（主要針對測試資料）\n",
    "    if data['Fare'].isnull().any():\n",
    "        fare_median = data['Fare'].median()\n",
    "        fare_missing_count = data['Fare'].isnull().sum()\n",
    "        data['Fare'].fillna(fare_median, inplace=True)\n",
    "        print(f\"✓ Fare: {fare_missing_count} 個缺失值用中位數 {fare_median:.2f} 填補\")\n",
    "    \n",
    "    # 3. 特徵工程\n",
    "    print(f\"\\n進行 {dataset_name} 的特徵工程...\")\n",
    "    \n",
    "    # 提取稱謂\n",
    "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "        'Capt': 'Rare', 'Sir': 'Rare'\n",
    "    }\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "    data['Title'].fillna('Rare', inplace=True)\n",
    "    \n",
    "    # 家庭相關特徵\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Cabin特徵：將缺失值轉換為有用的特徵\n",
    "    data['Has_Cabin'] = (~data['Cabin'].isnull()).astype(int)\n",
    "    cabin_missing_count = data['Cabin'].isnull().sum()\n",
    "    print(f\"✓ Cabin: {cabin_missing_count} 個缺失值轉換為 Has_Cabin 特徵\")\n",
    "    \n",
    "    # 票價對數轉換\n",
    "    data['Fare_log'] = np.log(data['Fare'] + 1)\n",
    "    \n",
    "    # 年齡分組\n",
    "    def categorize_age(age):\n",
    "        if age <= 11:\n",
    "            return 'Child(11以下)'\n",
    "        elif age <= 18:\n",
    "            return 'Teen(12-18)'\n",
    "        elif age <= 58:\n",
    "            return 'Adult(19-58)'\n",
    "        else:\n",
    "            return 'Senior(59以上)'\n",
    "    \n",
    "    data['Age_Group'] = data['Age'].apply(categorize_age)\n",
    "    \n",
    "    # 4. 最終檢查\n",
    "    analyze_missing_values(data, f\"{dataset_name}（處理後）\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"資料預處理函式定義完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 載入並預處理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料路徑\n",
    "train_path = r'C:\\Users\\jedi8\\Documents\\GitHub\\IanLi-Data-Analytics-Projects\\projects\\01_Exploratory_Data_Analysis\\001_EDA_Project_A_Titanic_Survival_Analysis\\data\\train.csv'\n",
    "test_path = r'C:\\Users\\jedi8\\Documents\\GitHub\\IanLi-Data-Analytics-Projects\\projects\\01_Exploratory_Data_Analysis\\001_EDA_Project_A_Titanic_Survival_Analysis\\data\\test.csv'\n",
    "\n",
    "# 載入原始資料\n",
    "print(\"載入原始資料...\")\n",
    "train_raw = pd.read_csv(train_path)\n",
    "test_raw = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"訓練資料: {train_raw.shape[0]} 筆, {train_raw.shape[1]} 欄\")\n",
    "print(f\"測試資料: {test_raw.shape[0]} 筆, {test_raw.shape[1]} 欄\")\n",
    "\n",
    "# 預處理資料\n",
    "train_processed = preprocess_titanic_data(train_raw, \"訓練資料\")\n",
    "test_processed = preprocess_titanic_data(test_raw, \"測試資料\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 準備模型訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義要移除的欄位\n",
    "features_to_drop = ['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch', 'Fare', 'Age', 'Cabin']\n",
    "target_column = 'Survived'\n",
    "\n",
    "# 準備訓練資料\n",
    "print(\"\\n準備訓練資料...\")\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Age_Group']\n",
    "train_encoded = pd.get_dummies(train_processed, columns=categorical_features, drop_first=True)\n",
    "\n",
    "y_train = train_encoded[target_column]\n",
    "X_train = train_encoded.drop(columns=[target_column] + features_to_drop, axis=1)\n",
    "X_train = X_train.apply(pd.to_numeric)\n",
    "\n",
    "# 記錄特徵欄位\n",
    "feature_columns = X_train.columns.tolist()\n",
    "\n",
    "print(f\"訓練特徵數量: {len(feature_columns)}\")\n",
    "print(f\"訓練樣本數: {len(X_train)}\")\n",
    "print(f\"\\n使用的特徵:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 準備測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備測試資料\n",
    "print(\"\\n準備測試資料...\")\n",
    "test_encoded = pd.get_dummies(test_processed, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 檢查是否有Survived欄位\n",
    "has_target = 'Survived' in test_encoded.columns\n",
    "print(f\"測試資料是否包含答案: {'是' if has_target else '否'}\")\n",
    "\n",
    "# 移除不需要的欄位\n",
    "columns_to_drop = features_to_drop.copy()\n",
    "if has_target:\n",
    "    columns_to_drop.append('Survived')\n",
    "\n",
    "X_test = test_encoded.drop(columns=[col for col in columns_to_drop if col in test_encoded.columns], axis=1)\n",
    "\n",
    "# 確保特徵一致性\n",
    "print(\"\\n檢查特徵一致性...\")\n",
    "missing_features = [col for col in feature_columns if col not in X_test.columns]\n",
    "extra_features = [col for col in X_test.columns if col not in feature_columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"添加缺失特徵: {missing_features}\")\n",
    "    for col in missing_features:\n",
    "        X_test[col] = 0\n",
    "\n",
    "if extra_features:\n",
    "    print(f\"移除多餘特徵: {extra_features}\")\n",
    "\n",
    "# 重新排序特徵\n",
    "X_test = X_test[feature_columns]\n",
    "X_test = X_test.apply(pd.to_numeric)\n",
    "\n",
    "# 提取目標變數（如果存在）\n",
    "y_test = test_encoded['Survived'] if has_target else None\n",
    "\n",
    "print(f\"測試樣本數: {len(X_test)}\")\n",
    "print(f\"特徵匹配: ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練羅吉斯迴歸模型\n",
    "print(\"\\n訓練羅吉斯迴歸模型...\")\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 訓練集預測\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"模型訓練完成！\")\n",
    "print(f\"訓練集準確率: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 測試資料預測與ROC分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對測試資料進行預測\n",
    "y_pred_test = log_reg.predict(X_test)\n",
    "y_pred_proba_test = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\n=== 測試資料預測結果 ===\")\n",
    "print(f\"預測生還: {np.sum(y_pred_test)} 人 ({np.mean(y_pred_test)*100:.1f}%)\")\n",
    "print(f\"預測未生還: {len(y_pred_test) - np.sum(y_pred_test)} 人 ({(1-np.mean(y_pred_test))*100:.1f}%)\")\n",
    "print(f\"平均預測機率: {np.mean(y_pred_proba_test):.4f}\")\n",
    "\n",
    "# 預測結果視覺化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 預測機率分布\n",
    "axes[0].hist(y_pred_proba_test, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('預測生還機率')\n",
    "axes[0].set_ylabel('乘客數量')\n",
    "axes[0].set_title('預測機率分布')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 預測結果分布\n",
    "survival_counts = pd.Series(y_pred_test).value_counts().sort_index()\n",
    "axes[1].bar(['未生還', '生還'], survival_counts.values, color=['red', 'green'], alpha=0.7)\n",
    "axes[1].set_ylabel('乘客數量')\n",
    "axes[1].set_title('預測結果分布')\n",
    "for i, v in enumerate(survival_counts.values):\n",
    "    axes[1].text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC分析（如果有真實答案）\n",
    "if y_test is not None:\n",
    "    print(f\"\\n=== ROC曲線分析 ===\")\n",
    "    \n",
    "    # 計算ROC曲線\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # 計算其他指標\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_precision = precision_score(y_test, y_pred_test)\n",
    "    test_recall = recall_score(y_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"測試集準確率: {test_accuracy:.4f}\")\n",
    "    print(f\"測試集精確率: {test_precision:.4f}\")\n",
    "    print(f\"測試集召回率: {test_recall:.4f}\")\n",
    "    print(f\"測試集F1分數: {test_f1:.4f}\")\n",
    "    print(f\"AUC值: {roc_auc:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n=== 注意 ===\")\n",
    "    print(\"測試資料不包含真實答案，無法進行ROC分析\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ROC曲線繪製（僅當有真實答案時）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_test is not None:\n",
    "    # 繪製ROC曲線\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC曲線 (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "             label='隨機分類器 (AUC = 0.5)')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('偽陽性率 (False Positive Rate)', fontsize=12)\n",
    "    plt.ylabel('真陽性率 (True Positive Rate)', fontsize=12)\n",
    "    plt.title('羅吉斯迴歸模型 - ROC曲線', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加AUC解釋\n",
    "    auc_interpretation = \"\"\n",
    "    if roc_auc > 0.9:\n",
    "        auc_interpretation = \"優秀\"\n",
    "    elif roc_auc > 0.8:\n",
    "        auc_interpretation = \"良好\"\n",
    "    elif roc_auc > 0.7:\n",
    "        auc_interpretation = \"尚可\"\n",
    "    elif roc_auc > 0.6:\n",
    "        auc_interpretation = \"較差\"\n",
    "    else:\n",
    "        auc_interpretation = \"無效\"\n",
    "    \n",
    "    plt.text(0.6, 0.2, \n",
    "             f'AUC = {roc_auc:.4f}\\n模型效能: {auc_interpretation}\\n\\n解釋:\\n• AUC > 0.9: 優秀\\n• AUC > 0.8: 良好\\n• AUC > 0.7: 尚可\\n• AUC > 0.6: 差\\n• AUC ≤ 0.5: 無效', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n",
    "             fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 找到最佳閾值\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\n最佳分類閾值: {optimal_threshold:.4f}\")\n",
    "    print(f\"在此閾值下，TPR = {tpr[optimal_idx]:.4f}, FPR = {fpr[optimal_idx]:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n由於測試資料沒有真實答案，無法繪製ROC曲線\")\n",
    "    print(\"如需ROC分析，請使用包含Survived欄位的測試資料\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 保存預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存預測結果\n",
    "if 'PassengerId' in test_raw.columns:\n",
    "    results_df = pd.DataFrame({\n",
    "        'PassengerId': test_raw['PassengerId'],\n",
    "        'Survived': y_pred_test,\n",
    "        'Survival_Probability': y_pred_proba_test\n",
    "    })\n",
    "else:\n",
    "    results_df = pd.DataFrame({\n",
    "        'Index': range(len(y_pred_test)),\n",
    "        'Survived': y_pred_test,\n",
    "        'Survival_Probability': y_pred_proba_test\n",
    "    })\n",
    "\n",
    "print(\"\\n=== 預測結果 ===\")\n",
    "print(\"前10筆預測結果:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# 保存到CSV\n",
    "output_path = '../data/titanic_predictions_roc_analysis.csv'\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n預測結果已保存至: {output_path}\")\n",
    "\n",
    "print(f\"\\n最終統計:\")\n",
    "print(f\"總樣本數: {len(results_df)}\")\n",
    "print(f\"預測生還: {results_df['Survived'].sum()} 人 ({results_df['Survived'].mean()*100:.1f}%)\")\n",
    "print(f\"預測未生還: {len(results_df) - results_df['Survived'].sum()} 人 ({(1-results_df['Survived'].mean())*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnalysisProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}